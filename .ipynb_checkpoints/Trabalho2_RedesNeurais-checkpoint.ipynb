{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd8c70a",
   "metadata": {},
   "source": [
    "# Trabalho 2 - Redes\n",
    "Criar um detector de anomalias usando pytorch. Faça um experimento com um dataset. Neste experimento você deve gerar o gráfico com curvas de erro de treino e de validação. Você deve escolher o melhor modelo de acordo com este gráfico e aplicar num conjunto de teste separado este modelo. Você deve ao final saber a taxa de acerto de anomalias vc não anomalias. Utilize métricas como f1 por classe e mcc (mathews correlation coeficient).\n",
    "\n",
    "Importante. Para a detecção de anomalias, é necessário a escolha (tanto devios padrão da média) ou calibração (conjunto de validação) de um limiar para o erro de reconstrução."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3668a43b",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Primeiro é preciso importar as bibliotecas e funções a serem utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594e94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37a36cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/creditcard.csv\")\n",
    "df[\"Time\"] = df[\"Time\"].apply(lambda x : x / 3600 % 24)\n",
    "y = df['Class']\n",
    "X = df.drop('Class', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "446fa37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.tensor(X_train.values.astype(np.float32))\n",
    "train_target = torch.tensor(X_train.values.astype(np.float32))\n",
    "train_tensor = data_utils.TensorDataset(train, train_target) \n",
    "train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0af89162",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = torch.tensor(X_test.values.astype(np.float32))\n",
    "test = torch.tensor(X_test.values.astype(np.float32)) \n",
    "test_tensor = data_utils.TensorDataset(test, test_target) \n",
    "test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa58b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dbc29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.autoencoder = nn.Sequential(\n",
    "            torch.nn.Linear(30, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 8),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(8, 4),\n",
    "            torch.nn.Linear(4, 8),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(8, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 30)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.autoencoder(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10ac3c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (autoencoder): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (5): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=8, out_features=16, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=16, out_features=30, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "953a09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dff2fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    loss_history = []\n",
    "    batch_history = []\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "                        \n",
    "            loss_history.append(loss)\n",
    "            batch_history.append(current)\n",
    "            \n",
    "    return loss_history, batch_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc10bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for X, y in dataloader:\n",
    "          pred = model(X)\n",
    "          test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct   /= size  \n",
    "    print(f\"Test Error: \\n Accuracy: {100*correct:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81a24fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------------------\n",
      "loss: 1628.358765 [    0/227845]\n",
      "loss: 1053.160522 [ 6400/227845]\n",
      "loss: 1080.104858 [12800/227845]\n",
      "loss: 712.869934 [19200/227845]\n",
      "loss: 390.994080 [25600/227845]\n",
      "loss: 550.815063 [32000/227845]\n",
      "loss: 1697.056885 [38400/227845]\n",
      "loss: 245.271011 [44800/227845]\n",
      "loss: 334.425446 [51200/227845]\n",
      "loss: 269.451080 [57600/227845]\n",
      "loss: 1449.752441 [64000/227845]\n",
      "loss: 1517.780640 [70400/227845]\n",
      "loss: 3977.324707 [76800/227845]\n",
      "loss: 727.254028 [83200/227845]\n",
      "loss: 493.111267 [89600/227845]\n",
      "loss: 2044.235718 [96000/227845]\n",
      "loss: 1516.672363 [102400/227845]\n",
      "loss: 1701.577637 [108800/227845]\n",
      "loss: 1394.666870 [115200/227845]\n",
      "loss: 35979.398438 [121600/227845]\n",
      "loss: 356.709381 [128000/227845]\n",
      "loss: 584.702393 [134400/227845]\n",
      "loss: 341915.187500 [140800/227845]\n",
      "loss: 348.034698 [147200/227845]\n",
      "loss: 385.774689 [153600/227845]\n",
      "loss: 1887.979614 [160000/227845]\n",
      "loss: 510.031708 [166400/227845]\n",
      "loss: 1007.337769 [172800/227845]\n",
      "loss: 1422.181152 [179200/227845]\n",
      "loss: 8664.623047 [185600/227845]\n",
      "loss: 2013.912231 [192000/227845]\n",
      "loss: 431.195221 [198400/227845]\n",
      "loss: 2441.510498 [204800/227845]\n",
      "loss: 758.497375 [211200/227845]\n",
      "loss: 1505.169312 [217600/227845]\n",
      "loss: 954.514099 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.560700 \n",
      "\n",
      "Epoch 2\n",
      "-----------------------------------\n",
      "loss: 356.290314 [    0/227845]\n",
      "loss: 1123.143799 [ 6400/227845]\n",
      "loss: 6719.911133 [12800/227845]\n",
      "loss: 3595.568604 [19200/227845]\n",
      "loss: 1321.871338 [25600/227845]\n",
      "loss: 809.838623 [32000/227845]\n",
      "loss: 1068.169067 [38400/227845]\n",
      "loss: 461.681000 [44800/227845]\n",
      "loss: 555.595886 [51200/227845]\n",
      "loss: 475.250336 [57600/227845]\n",
      "loss: 703.427979 [64000/227845]\n",
      "loss: 1353.557007 [70400/227845]\n",
      "loss: 2175.309082 [76800/227845]\n",
      "loss: 254.239059 [83200/227845]\n",
      "loss: 1274.330933 [89600/227845]\n",
      "loss: 834.456848 [96000/227845]\n",
      "loss: 353.815552 [102400/227845]\n",
      "loss: 9089.458008 [108800/227845]\n",
      "loss: 950.679321 [115200/227845]\n",
      "loss: 13088.136719 [121600/227845]\n",
      "loss: 1250.871582 [128000/227845]\n",
      "loss: 442.887024 [134400/227845]\n",
      "loss: 1225.045166 [140800/227845]\n",
      "loss: 599.757568 [147200/227845]\n",
      "loss: 675.582581 [153600/227845]\n",
      "loss: 3574.264893 [160000/227845]\n",
      "loss: 290.566742 [166400/227845]\n",
      "loss: 3787.303711 [172800/227845]\n",
      "loss: 927.111023 [179200/227845]\n",
      "loss: 2233.496826 [185600/227845]\n",
      "loss: 408.991180 [192000/227845]\n",
      "loss: 26243.205078 [198400/227845]\n",
      "loss: 424.946777 [204800/227845]\n",
      "loss: 1991.578857 [211200/227845]\n",
      "loss: 245.102188 [217600/227845]\n",
      "loss: 987.102478 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.558450 \n",
      "\n",
      "Epoch 3\n",
      "-----------------------------------\n",
      "loss: 670.163330 [    0/227845]\n",
      "loss: 1691.931763 [ 6400/227845]\n",
      "loss: 2552.620117 [12800/227845]\n",
      "loss: 8937.685547 [19200/227845]\n",
      "loss: 373.305939 [25600/227845]\n",
      "loss: 917.838074 [32000/227845]\n",
      "loss: 8719.995117 [38400/227845]\n",
      "loss: 535.255859 [44800/227845]\n",
      "loss: 341.338562 [51200/227845]\n",
      "loss: 7326.475586 [57600/227845]\n",
      "loss: 1605.993896 [64000/227845]\n",
      "loss: 3375.414551 [70400/227845]\n",
      "loss: 1185.848999 [76800/227845]\n",
      "loss: 761.574219 [83200/227845]\n",
      "loss: 3085.766113 [89600/227845]\n",
      "loss: 603.636658 [96000/227845]\n",
      "loss: 5116.126953 [102400/227845]\n",
      "loss: 818.791016 [108800/227845]\n",
      "loss: 628.543518 [115200/227845]\n",
      "loss: 619.885132 [121600/227845]\n",
      "loss: 1043.912598 [128000/227845]\n",
      "loss: 869.682190 [134400/227845]\n",
      "loss: 321.703705 [140800/227845]\n",
      "loss: 900.497253 [147200/227845]\n",
      "loss: 635.907410 [153600/227845]\n",
      "loss: 6845.586914 [160000/227845]\n",
      "loss: 965.446411 [166400/227845]\n",
      "loss: 5361.156250 [172800/227845]\n",
      "loss: 970.177002 [179200/227845]\n",
      "loss: 3618.343994 [185600/227845]\n",
      "loss: 1223.276855 [192000/227845]\n",
      "loss: 237.243668 [198400/227845]\n",
      "loss: 658.362488 [204800/227845]\n",
      "loss: 514.391235 [211200/227845]\n",
      "loss: 439.249603 [217600/227845]\n",
      "loss: 1457.093018 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.693296 \n",
      "\n",
      "Epoch 4\n",
      "-----------------------------------\n",
      "loss: 965.489990 [    0/227845]\n",
      "loss: 392.875580 [ 6400/227845]\n",
      "loss: 335.207153 [12800/227845]\n",
      "loss: 927.748901 [19200/227845]\n",
      "loss: 906.395203 [25600/227845]\n",
      "loss: 2010.565918 [32000/227845]\n",
      "loss: 2230.848145 [38400/227845]\n",
      "loss: 429.521545 [44800/227845]\n",
      "loss: 1335.003784 [51200/227845]\n",
      "loss: 13437.998047 [57600/227845]\n",
      "loss: 747.783569 [64000/227845]\n",
      "loss: 2065.132568 [70400/227845]\n",
      "loss: 3734.160889 [76800/227845]\n",
      "loss: 1025.691406 [83200/227845]\n",
      "loss: 1494.327393 [89600/227845]\n",
      "loss: 322.248322 [96000/227845]\n",
      "loss: 455.053619 [102400/227845]\n",
      "loss: 255.603134 [108800/227845]\n",
      "loss: 1952.080322 [115200/227845]\n",
      "loss: 742.839905 [121600/227845]\n",
      "loss: 2840.889160 [128000/227845]\n",
      "loss: 425.220245 [134400/227845]\n",
      "loss: 759.746216 [140800/227845]\n",
      "loss: 1505.270874 [147200/227845]\n",
      "loss: 564.914185 [153600/227845]\n",
      "loss: 1558.062866 [160000/227845]\n",
      "loss: 431.220154 [166400/227845]\n",
      "loss: 2171.148193 [172800/227845]\n",
      "loss: 5507.783203 [179200/227845]\n",
      "loss: 2319.245605 [185600/227845]\n",
      "loss: 282.092773 [192000/227845]\n",
      "loss: 1346.399170 [198400/227845]\n",
      "loss: 493.600769 [204800/227845]\n",
      "loss: 265.766418 [211200/227845]\n",
      "loss: 1399.397217 [217600/227845]\n",
      "loss: 244.952194 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.556903 \n",
      "\n",
      "Epoch 5\n",
      "-----------------------------------\n",
      "loss: 1125.237061 [    0/227845]\n",
      "loss: 518.696106 [ 6400/227845]\n",
      "loss: 1430.454712 [12800/227845]\n",
      "loss: 478.205200 [19200/227845]\n",
      "loss: 247.190155 [25600/227845]\n",
      "loss: 318.005920 [32000/227845]\n",
      "loss: 304.273041 [38400/227845]\n",
      "loss: 759.313599 [44800/227845]\n",
      "loss: 651.979065 [51200/227845]\n",
      "loss: 466.995972 [57600/227845]\n",
      "loss: 17783.396484 [64000/227845]\n",
      "loss: 537.846375 [70400/227845]\n",
      "loss: 897.411072 [76800/227845]\n",
      "loss: 5864.022949 [83200/227845]\n",
      "loss: 4437.489258 [89600/227845]\n",
      "loss: 306.579681 [96000/227845]\n",
      "loss: 533.936890 [102400/227845]\n",
      "loss: 653.686584 [108800/227845]\n",
      "loss: 869.384827 [115200/227845]\n",
      "loss: 591.275269 [121600/227845]\n",
      "loss: 1358.265625 [128000/227845]\n",
      "loss: 653.949768 [134400/227845]\n",
      "loss: 410.521301 [140800/227845]\n",
      "loss: 844.201538 [147200/227845]\n",
      "loss: 565.885620 [153600/227845]\n",
      "loss: 1296.520752 [160000/227845]\n",
      "loss: 188.637070 [166400/227845]\n",
      "loss: 704.200195 [172800/227845]\n",
      "loss: 728.002930 [179200/227845]\n",
      "loss: 428.359650 [185600/227845]\n",
      "loss: 1444.443970 [192000/227845]\n",
      "loss: 682.065125 [198400/227845]\n",
      "loss: 1281.735474 [204800/227845]\n",
      "loss: 668.924622 [211200/227845]\n",
      "loss: 4297.022949 [217600/227845]\n",
      "loss: 817.819641 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.561284 \n",
      "\n",
      "Epoch 6\n",
      "-----------------------------------\n",
      "loss: 1839.804199 [    0/227845]\n",
      "loss: 11618.571289 [ 6400/227845]\n",
      "loss: 580.951599 [12800/227845]\n",
      "loss: 1565.207520 [19200/227845]\n",
      "loss: 992.843872 [25600/227845]\n",
      "loss: 550.707764 [32000/227845]\n",
      "loss: 357.508148 [38400/227845]\n",
      "loss: 1487.552368 [44800/227845]\n",
      "loss: 1706.744263 [51200/227845]\n",
      "loss: 171.013992 [57600/227845]\n",
      "loss: 2978.729980 [64000/227845]\n",
      "loss: 689.741516 [70400/227845]\n",
      "loss: 1627.937012 [76800/227845]\n",
      "loss: 3188.637695 [83200/227845]\n",
      "loss: 541.116150 [89600/227845]\n",
      "loss: 38898.433594 [96000/227845]\n",
      "loss: 263.082581 [102400/227845]\n",
      "loss: 1861.007812 [108800/227845]\n",
      "loss: 4726.073730 [115200/227845]\n",
      "loss: 2117.842041 [121600/227845]\n",
      "loss: 2543.371338 [128000/227845]\n",
      "loss: 451.611908 [134400/227845]\n",
      "loss: 989.245728 [140800/227845]\n",
      "loss: 12619.817383 [147200/227845]\n",
      "loss: 1036.660889 [153600/227845]\n",
      "loss: 492.852844 [160000/227845]\n",
      "loss: 2102.983643 [166400/227845]\n",
      "loss: 360.394897 [172800/227845]\n",
      "loss: 350.283722 [179200/227845]\n",
      "loss: 1091.535400 [185600/227845]\n",
      "loss: 537.126587 [192000/227845]\n",
      "loss: 275.442535 [198400/227845]\n",
      "loss: 13159.750000 [204800/227845]\n",
      "loss: 282.466309 [211200/227845]\n",
      "loss: 722.751953 [217600/227845]\n",
      "loss: 2772.961670 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.560278 \n",
      "\n",
      "Epoch 7\n",
      "-----------------------------------\n",
      "loss: 2158.425537 [    0/227845]\n",
      "loss: 394.066345 [ 6400/227845]\n",
      "loss: 1575.579834 [12800/227845]\n",
      "loss: 13836.815430 [19200/227845]\n",
      "loss: 1808.539551 [25600/227845]\n",
      "loss: 758.280945 [32000/227845]\n",
      "loss: 308.883301 [38400/227845]\n",
      "loss: 505.201355 [44800/227845]\n",
      "loss: 1020.053406 [51200/227845]\n",
      "loss: 1503.423218 [57600/227845]\n",
      "loss: 539.142639 [64000/227845]\n",
      "loss: 1395.324341 [70400/227845]\n",
      "loss: 509.363556 [76800/227845]\n",
      "loss: 907.296082 [83200/227845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 974.345093 [89600/227845]\n",
      "loss: 2057.885498 [96000/227845]\n",
      "loss: 408.443695 [102400/227845]\n",
      "loss: 319.407410 [108800/227845]\n",
      "loss: 1858.038696 [115200/227845]\n",
      "loss: 388.467651 [121600/227845]\n",
      "loss: 1559.246826 [128000/227845]\n",
      "loss: 399.226227 [134400/227845]\n",
      "loss: 287.955292 [140800/227845]\n",
      "loss: 215.487640 [147200/227845]\n",
      "loss: 922.305237 [153600/227845]\n",
      "loss: 3363.707764 [160000/227845]\n",
      "loss: 1021.307007 [166400/227845]\n",
      "loss: 295.991577 [172800/227845]\n",
      "loss: 2549.912354 [179200/227845]\n",
      "loss: 629.899780 [185600/227845]\n",
      "loss: 231.352646 [192000/227845]\n",
      "loss: 11781.158203 [198400/227845]\n",
      "loss: 332.823730 [204800/227845]\n",
      "loss: 669.564331 [211200/227845]\n",
      "loss: 7509.319336 [217600/227845]\n",
      "loss: 2571.292236 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.559310 \n",
      "\n",
      "Epoch 8\n",
      "-----------------------------------\n",
      "loss: 315.859985 [    0/227845]\n",
      "loss: 1507.178467 [ 6400/227845]\n",
      "loss: 812.703857 [12800/227845]\n",
      "loss: 330.524048 [19200/227845]\n",
      "loss: 343.722076 [25600/227845]\n",
      "loss: 2106.299316 [32000/227845]\n",
      "loss: 1078.991333 [38400/227845]\n",
      "loss: 1587.088501 [44800/227845]\n",
      "loss: 928.161194 [51200/227845]\n",
      "loss: 932.772522 [57600/227845]\n",
      "loss: 359.612946 [64000/227845]\n",
      "loss: 1294.776489 [70400/227845]\n",
      "loss: 573.705811 [76800/227845]\n",
      "loss: 670.584045 [83200/227845]\n",
      "loss: 492.490997 [89600/227845]\n",
      "loss: 989.122742 [96000/227845]\n",
      "loss: 797.883179 [102400/227845]\n",
      "loss: 2768.879395 [108800/227845]\n",
      "loss: 1280.841797 [115200/227845]\n",
      "loss: 2350.886475 [121600/227845]\n",
      "loss: 248.022949 [128000/227845]\n",
      "loss: 1428.803101 [134400/227845]\n",
      "loss: 212.009903 [140800/227845]\n",
      "loss: 24318.019531 [147200/227845]\n",
      "loss: 623.355530 [153600/227845]\n",
      "loss: 832.496338 [160000/227845]\n",
      "loss: 798.225830 [166400/227845]\n",
      "loss: 382.026917 [172800/227845]\n",
      "loss: 3377.572510 [179200/227845]\n",
      "loss: 1039.482544 [185600/227845]\n",
      "loss: 945.993591 [192000/227845]\n",
      "loss: 2261.875488 [198400/227845]\n",
      "loss: 573.038330 [204800/227845]\n",
      "loss: 905.691223 [211200/227845]\n",
      "loss: 1974.286255 [217600/227845]\n",
      "loss: 226.232910 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.557341 \n",
      "\n",
      "Epoch 9\n",
      "-----------------------------------\n",
      "loss: 277.002930 [    0/227845]\n",
      "loss: 1910.757446 [ 6400/227845]\n",
      "loss: 2435.260986 [12800/227845]\n",
      "loss: 3002.224121 [19200/227845]\n",
      "loss: 337.095612 [25600/227845]\n",
      "loss: 801.451965 [32000/227845]\n",
      "loss: 3895.964355 [38400/227845]\n",
      "loss: 1597.203369 [44800/227845]\n",
      "loss: 661.303833 [51200/227845]\n",
      "loss: 161.380203 [57600/227845]\n",
      "loss: 293.264557 [64000/227845]\n",
      "loss: 1564.376099 [70400/227845]\n",
      "loss: 680.455750 [76800/227845]\n",
      "loss: 1283.667480 [83200/227845]\n",
      "loss: 1315.250610 [89600/227845]\n",
      "loss: 1556.151489 [96000/227845]\n",
      "loss: 2964.795654 [102400/227845]\n",
      "loss: 1111.628418 [108800/227845]\n",
      "loss: 566.681702 [115200/227845]\n",
      "loss: 293.935577 [121600/227845]\n",
      "loss: 994.369324 [128000/227845]\n",
      "loss: 736.610107 [134400/227845]\n",
      "loss: 835.914856 [140800/227845]\n",
      "loss: 786.682922 [147200/227845]\n",
      "loss: 1317.308960 [153600/227845]\n",
      "loss: 280.053192 [160000/227845]\n",
      "loss: 5930.232910 [166400/227845]\n",
      "loss: 3788.427979 [172800/227845]\n",
      "loss: 325.581665 [179200/227845]\n",
      "loss: 1555.272949 [185600/227845]\n",
      "loss: 3401.038574 [192000/227845]\n",
      "loss: 858.815552 [198400/227845]\n",
      "loss: 1111.151978 [204800/227845]\n",
      "loss: 1916.697144 [211200/227845]\n",
      "loss: 1712.239990 [217600/227845]\n",
      "loss: 459.887085 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.559692 \n",
      "\n",
      "Epoch 10\n",
      "-----------------------------------\n",
      "loss: 643.893494 [    0/227845]\n",
      "loss: 426.804504 [ 6400/227845]\n",
      "loss: 407.809113 [12800/227845]\n",
      "loss: 321.659943 [19200/227845]\n",
      "loss: 2152.033936 [25600/227845]\n",
      "loss: 911.189575 [32000/227845]\n",
      "loss: 5100.799805 [38400/227845]\n",
      "loss: 681.153687 [44800/227845]\n",
      "loss: 586.084900 [51200/227845]\n",
      "loss: 1388.594238 [57600/227845]\n",
      "loss: 3001.001465 [64000/227845]\n",
      "loss: 1150.103149 [70400/227845]\n",
      "loss: 626.565613 [76800/227845]\n",
      "loss: 1425.547119 [83200/227845]\n",
      "loss: 1540.886963 [89600/227845]\n",
      "loss: 550.905945 [96000/227845]\n",
      "loss: 1694.781982 [102400/227845]\n",
      "loss: 1336.707031 [108800/227845]\n",
      "loss: 1255.958740 [115200/227845]\n",
      "loss: 929.150940 [121600/227845]\n",
      "loss: 705.549927 [128000/227845]\n",
      "loss: 1385.738403 [134400/227845]\n",
      "loss: 2425.298096 [140800/227845]\n",
      "loss: 1390.294556 [147200/227845]\n",
      "loss: 367.661926 [153600/227845]\n",
      "loss: 482.374542 [160000/227845]\n",
      "loss: 640.929016 [166400/227845]\n",
      "loss: 736.596130 [172800/227845]\n",
      "loss: 535.066895 [179200/227845]\n",
      "loss: 349.365112 [185600/227845]\n",
      "loss: 252.735565 [192000/227845]\n",
      "loss: 631.010315 [198400/227845]\n",
      "loss: 853.553467 [204800/227845]\n",
      "loss: 1662.589600 [211200/227845]\n",
      "loss: 705.622192 [217600/227845]\n",
      "loss: 571.544250 [224000/227845]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 27.557502 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_test_history = []\n",
    "acc_history = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------------------\")\n",
    "    loss_train_history, batch_history = train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    loss, accuracy = test_loop(test_loader, model, loss_fn)\n",
    "    loss_test_history.append(loss)\n",
    "    acc_history.append(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
